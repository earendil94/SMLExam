{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earendil94/SMLExam/blob/preferivolescimmie/Project_leo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLD803bQHlrZ",
        "colab_type": "text"
      },
      "source": [
        "**STATISTICAL MACHINE LEARNING**\n",
        "\n",
        "ARRIGHI Leonardo, BRAND Francesco, DORIGO Claudia\n",
        "\n",
        "\n",
        "Dataset folder is saved in \"/content/drive/My Drive/SML/SML_Project\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADn7VmfFHe_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "048b4259-7db4-49f8-e4ab-c17f309e3955"
      },
      "source": [
        "# link colab and drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "# then follow passages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqQgtn1AuSAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92995064-1eb5-4d2e-dddf-cddba3c4952b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from IPython import display\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "torch.manual_seed(160898)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device: {}'.format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eycNavNlqLPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4ddae88-03ef-445e-908d-8a08f3c06e65"
      },
      "source": [
        "csv = '/content/drive/My Drive/SML/SML_Project/Chunk1/results.csv'\n",
        "imgs = '/content/drive/My\\ Drive/SML/SML_Project/Chunk1/img1_200/'\n",
        "\n",
        "!ls {imgs} | wc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    200     200    2382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmvRFfu92TsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "b410259e-1356-49a7-8102-b1217c44fc29"
      },
      "source": [
        "# Load csv\n",
        "df = pd.read_csv(csv, delimiter='|') \n",
        "print(df.shape)\n",
        "print(df.columns[2], df.columns[2] == ' comment') \n",
        "df[' comment'].values[0]\n",
        "df.head(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(158915, 3)\n",
            " comment True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>comment_number</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>Two young guys with shaggy hair look at their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Two young , White males are outside near many...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>Two men in green shirts are standing in a yard .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>A man in a blue shirt standing in a garden .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000092795.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>Two friends enjoy time spent together .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10002456.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>Several men in hard hats are operating a gian...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_name  ...                                            comment\n",
              "0  1000092795.jpg  ...   Two young guys with shaggy hair look at their...\n",
              "1  1000092795.jpg  ...   Two young , White males are outside near many...\n",
              "2  1000092795.jpg  ...   Two men in green shirts are standing in a yard .\n",
              "3  1000092795.jpg  ...       A man in a blue shirt standing in a garden .\n",
              "4  1000092795.jpg  ...            Two friends enjoy time spent together .\n",
              "5    10002456.jpg  ...   Several men in hard hats are operating a gian...\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve62VVO-SrFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load images\n",
        "# needed transformation: to tensor and normalize\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "input_images = []\n",
        "for filename in glob.glob(\"/content/drive/My Drive/SML/SML_Project/Chunk1/img1_200/*.jpg\"):\n",
        "    im=Image.open(filename)\n",
        "    im=transform(im) # apply transformation while loading\n",
        "    input_images.append(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH9C27vHT9RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4ec51412-695e-49bb-8b34-17b8a8ceee05"
      },
      "source": [
        "for i in range(10):\n",
        "  print(input_images[i].shape)\n",
        "# not all images have the same shape but it shouldn't be a problem for ResNet\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 500, 335])\n",
            "torch.Size([3, 375, 500])\n",
            "torch.Size([3, 332, 500])\n",
            "torch.Size([3, 450, 450])\n",
            "torch.Size([3, 338, 450])\n",
            "torch.Size([3, 500, 375])\n",
            "torch.Size([3, 375, 500])\n",
            "torch.Size([3, 374, 500])\n",
            "torch.Size([3, 338, 450])\n",
            "torch.Size([3, 333, 500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdSOKP_OpM4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "\n",
        "# Model parameters\n",
        "#decoder_dim = \n",
        "dropout = 0.5 # suggested\n",
        "\n",
        "# Parameters\n",
        "epoch = 1000\n",
        "start_epoch = 0\n",
        "epochs_since_improvement = 0 # keeps track of number of epochs since there's been an improvement in validation BLEU\n",
        "batch_size = 32\n",
        "decoder_lr = 1e-4  # learning rate\n",
        "checkpoint = None\n",
        "bleu4 = 0. # bleu score -> https://www.aclweb.org/anthology/P02-1040.pdf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h310E0RxOnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# maybe this should be saved in a utils.py file\n",
        "\n",
        "def adjust_learning_rate(optimizer, shrink_factor):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = param_group['lr'] * shrink_factor\n",
        "\n",
        "def clip_gradient(optimizer, grad_clip):\n",
        "  for i in optimizer.param_groups:\n",
        "    for param in group['params']:\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkllCpdQvygE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "dedd0105-bd87-4587-9ef5-22ace2d1bbd3"
      },
      "source": [
        "# Vocabulary\n",
        "\n",
        "# Decoder\n",
        "#decoder = RNN(decoder_dim, vocabolary_size, dropout = dropout)\n",
        "\n",
        "decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, \n",
        "                                                   decoder.parameters()),\n",
        "                                     lr=decoder_lr)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Epochs\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
        "  if epochs_since_improvement == 20:\n",
        "    break\n",
        "  if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
        "    adjust_learning_rate(decoder_optimizer, 0.8)\n",
        "\n",
        "  # Training\n",
        "  train(train_loader=train_loader,\n",
        "        decoder=decoder,\n",
        "        criterion=criterion,\n",
        "        decoder_optimizer=decoder_optimizer,\n",
        "        epoch=epoch)\n",
        "  \n",
        "  # Validation\n",
        "  #bleu4_new\n",
        "\n",
        "  # BLEU4\n",
        "  flag1 = bleu4_new > bleu4\n",
        "  bleu4 = max(bleu4_new, bleu4)\n",
        "  if not flag1:\n",
        "    epochs_since_improvement += 1\n",
        "  else:\n",
        "    epochs_since_improvement = 0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b4f7c9b96df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_atm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqV8W_VlqUw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, decoder, criterion, decoder_optimizer, epoch):\n",
        "\n",
        "  decoder.train() # train mode\n",
        "\n",
        "  # Batch\n",
        "  for i, (image, caption, captionlen) in enumerate(train_loader):\n",
        "    \n",
        "    # Move to GPU, if available\n",
        "    image = image.to(device)\n",
        "    caption = caption.to(device)\n",
        "    captionlen = captionlen.to(device)\n",
        "\n",
        "    # Forward \n",
        "    #decoder output = decoder(image, caption, captionlen)\n",
        "\n",
        "    # Remove timesteps that we didn't decode at, or are pads\n",
        "    # https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pack_padded_sequence.html\n",
        "    # https://www.tensorflow.org/tutorials/text/image_captioning\n",
        "    scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
        "    targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(scores, targets)\n",
        "\n",
        "    # Back propagation\n",
        "    decoder_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients\n",
        "    # https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/\n",
        "    if grad_clip is not None:\n",
        "      clip_gradient(decoder_optimizer, grad_clip)\n",
        "\n",
        "    # Update weights\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}